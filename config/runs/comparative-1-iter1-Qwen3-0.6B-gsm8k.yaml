run_id: comparative-1-iter1-Qwen3-0.6B-gsm8k
method: BLuR-CANA
model:
  name: Qwen/Qwen3-0.6B
  peft:
    technique: lora
    r: 16
    alpha: 32
    dropout: 0.05
  quantisation:
    bits: 8
dataset:
  name: gsm8k
  config: main
  split_ratio:
    train: 0.9
    val: 0.1
  max_length: 512
  preprocessing:
    remove_calculation_annotations: false
training:
  optimiser: AdamW
  learning_rate: 2.0e-4
  lr_scheduler: BLuR-CANA
  lr_decay_gamma: 0.5
  min_lr_scaling: 0.05
  weight_decay: 0.0
  gradient_clip_norm: 1.0
  micro_batch_size: 16
  max_steps: 6000
  reactive_controller:
    overshoot_margin_g: 15
    carbon_budget_g: 120
    money_budget_eur: 0.12
  validation:
    every_n_tokens: 1000
    metrics: [gsm1k_accuracy]
  carbon_monitor:
    sample_interval_s: 5
    power_meter: nvidia_smi
optuna:
  n_trials: 40
  direction: maximize
  search_space:
    lr_decay_gamma:
      type: uniform
      low: 0.2
      high: 0.9
    min_lr_scaling:
      type: loguniform
      low: 0.05
      high: 0.2
    overshoot_margin_g:
      type: int
      low: 5
      high: 30
